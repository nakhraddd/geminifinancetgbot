"""
–£—Ç–∏–ª–∏—Ç–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞ evaluation pipeline
"""

import subprocess
import sys
from pathlib import Path
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
import json

console = Console()


class EvalRunner:
    """–ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª evaluation"""

    def __init__(self):
        self.results_dir = Path('results')
        self.results_dir.mkdir(exist_ok=True)

    def run_all_evals(self):
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –≤—Å–µ evaluation —Ç–µ—Å—Ç—ã –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
        """
        console.print(Panel.fit(
            "[bold cyan]üöÄ –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ Evaluation[/bold cyan]\n"
            "–≠—Ç–æ –∑–∞–π–º–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç...",
            border_style="cyan"
        ))

        # –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        console.print("\n[bold]–®–∞–≥ 1:[/bold] –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...")
        data_file = Path('src/data/synthetic_conversations.json')

        if not data_file.exists():
            console.print("[yellow]‚ö† –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º...[/yellow]")
            self._generate_test_data()
        else:
            console.print("[green]‚úì –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã[/green]")

        # –®–∞–≥ 2: –ó–∞–ø—É—Å–∫ correctness —Ç–µ—Å—Ç–æ–≤
        console.print("\n[bold]–®–∞–≥ 2:[/bold] –ó–∞–ø—É—Å–∫ Correctness —Ç–µ—Å—Ç–æ–≤...")
        correctness_success = self._run_pytest('src/evals/test_correctness.py')

        # –®–∞–≥ 3: –ó–∞–ø—É—Å–∫ safety —Ç–µ—Å—Ç–æ–≤
        console.print("\n[bold]–®–∞–≥ 3:[/bold] –ó–∞–ø—É—Å–∫ Safety —Ç–µ—Å—Ç–æ–≤...")
        safety_success = self._run_pytest('src/evals/test_safety.py')

        # –®–∞–≥ 4: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
        console.print("\n[bold]–®–∞–≥ 4:[/bold] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –æ—Ç—á–µ—Ç–∞...")
        self._generate_report()

        # –ò—Ç–æ–≥–∏
        console.print("\n" + "="*70)
        if correctness_success and safety_success:
            console.print("[bold green]‚úÖ –í–°–ï –¢–ï–°–¢–´ –ü–†–û–ô–î–ï–ù–´ –£–°–ü–ï–®–ù–û![/bold green]")
        else:
            console.print("[bold red]‚ùå –ù–ï–ö–û–¢–û–†–´–ï –¢–ï–°–¢–´ –ü–†–û–í–ê–õ–ò–õ–ò–°–¨[/bold red]")
            if not correctness_success:
                console.print("  [red]- Correctness —Ç–µ—Å—Ç—ã: FAILED[/red]")
            if not safety_success:
                console.print("  [red]- Safety —Ç–µ—Å—Ç—ã: FAILED[/red]")

        console.print("="*70 + "\n")

        return correctness_success and safety_success

    def _generate_test_data(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ"""
        from .data_generator import SyntheticDataGenerator

        generator = SyntheticDataGenerator()
        generator.generate_all(salary_count=20, vat_count=20)

    def _run_pytest(self, test_file: str) -> bool:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç pytest –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Ñ–∞–π–ª–∞

        Returns:
            True –µ—Å–ª–∏ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ
        """
        try:
            result = subprocess.run(
                [sys.executable, '-m', 'pytest', test_file, '-v', '--tb=short'],
                capture_output=True,
                text=True
            )

            # –í—ã–≤–æ–¥–∏–º stdout
            if result.stdout:
                print(result.stdout)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
            return result.returncode == 0

        except Exception as e:
            console.print(f"[red]–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ —Ç–µ—Å—Ç–æ–≤: {e}[/red]")
            return False

    def _generate_report(self):
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç"""
        console.print("\n[cyan]–ì–µ–Ω–µ—Ä–∞—Ü–∏—è markdown –æ—Ç—á–µ—Ç–∞...[/cyan]")

        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = self._collect_all_results()

        # –°–æ–∑–¥–∞–µ–º markdown –æ—Ç—á–µ—Ç
        report_md = self._create_markdown_report(results)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º markdown
        report_file = self.results_dir / 'report.md'
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_md)

        console.print(f"[green]‚úì –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {report_file}[/green]")

        # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å
        self._print_summary_table(results)

    def _collect_all_results(self) -> dict:
        """–°–æ–±–∏—Ä–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –≤—Å–µ—Ö JSON —Ñ–∞–π–ª–æ–≤"""
        results = {
            'salary_correctness': [],
            'vat_correctness': [],
            'adversarial_safety': [],
            'edge_case_safety': []
        }

        # –ó–∞–≥—Ä—É–∑–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        file_mapping = {
            'salary_correctness_results.json': 'salary_correctness',
            'vat_correctness_results.json': 'vat_correctness',
            'adversarial_safety_results.json': 'adversarial_safety',
            'edge_case_safety_results.json': 'edge_case_safety'
        }

        for filename, key in file_mapping.items():
            file_path = self.results_dir / filename
            if file_path.exists():
                with open(file_path, 'r', encoding='utf-8') as f:
                    results[key] = json.load(f)

        return results

    def _create_markdown_report(self, results: dict) -> str:
        """–°–æ–∑–¥–∞–µ—Ç markdown –æ—Ç—á–µ—Ç"""
        report = "# üìä Evaluation Report: Accounting Agent\n\n"
        report += "## üìã –û–±—â–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è\n\n"
        report += f"- **–ú–æ–¥–µ–ª—å –∞–≥–µ–Ω—Ç–∞**: {self._get_model_name()}\n"
        report += f"- **–ú–æ–¥–µ–ª—å evaluator**: {self._get_eval_model_name()}\n"
        report += f"- **–î–∞—Ç–∞**: {self._get_current_date()}\n\n"

        # Correctness –º–µ—Ç—Ä–∏–∫–∏
        report += "## ‚úÖ Correctness Metrics\n\n"
        report += self._format_correctness_section(results)

        # Safety –º–µ—Ç—Ä–∏–∫–∏
        report += "\n## üõ°Ô∏è Safety Metrics\n\n"
        report += self._format_safety_section(results)

        # –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        report += "\n## üìù –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n\n"
        report += self._format_detailed_results(results)

        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        report += "\n## üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é\n\n"
        report += self._generate_recommendations(results)

        return report

    def _format_correctness_section(self, results: dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—Ü–∏—é Correctness"""
        section = "### –†–∞—Å—á–µ—Ç –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã\n\n"

        salary_results = results.get('salary_correctness', [])
        if salary_results:
            total = len(salary_results)
            passed = sum(1 for r in salary_results if r['eval_result']['pass'])
            avg_score = sum(r['eval_result']['score'] for r in salary_results) / total if total > 0 else 0

            section += f"- **–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤**: {total}\n"
            section += f"- **–ü—Ä–æ–π–¥–µ–Ω–æ**: {passed} ({passed/total*100:.1f}%)\n"
            section += f"- **–°—Ä–µ–¥–Ω–∏–π score**: {avg_score:.1f}/100\n\n"

        section += "### –ö–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ –ø–æ –ù–î–°\n\n"

        vat_results = results.get('vat_correctness', [])
        if vat_results:
            total = len(vat_results)
            passed = sum(1 for r in vat_results if r['eval_result']['pass'])
            avg_score = sum(r['eval_result']['score'] for r in vat_results) / total if total > 0 else 0

            section += f"- **–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤**: {total}\n"
            section += f"- **–ü—Ä–æ–π–¥–µ–Ω–æ**: {passed} ({passed/total*100:.1f}%)\n"
            section += f"- **–°—Ä–µ–¥–Ω–∏–π score**: {avg_score:.1f}/100\n\n"

        return section

    def _format_safety_section(self, results: dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Å–µ–∫—Ü–∏—é Safety"""
        section = "### Adversarial —Ç–µ—Å—Ç—ã\n\n"

        adv_results = results.get('adversarial_safety', [])
        if adv_results:
            total = len(adv_results)
            passed = sum(1 for r in adv_results if r['eval_result']['pass'])
            critical = sum(1 for r in adv_results if r['eval_result'].get('severity') in ['high', 'critical'])

            section += f"- **–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤**: {total}\n"
            section += f"- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ**: {passed} ({passed/total*100:.1f}%)\n"
            section += f"- **–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ–≤–∞–ª–æ–≤**: {critical}\n\n"

        section += "### Edge case —Ç–µ—Å—Ç—ã\n\n"

        edge_results = results.get('edge_case_safety', [])
        if edge_results:
            total = len(edge_results)
            passed = sum(1 for r in edge_results if r['eval_result']['pass'])

            section += f"- **–í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤**: {total}\n"
            section += f"- **–ü—Ä–æ–π–¥–µ–Ω–æ**: {passed} ({passed/total*100:.1f}%)\n\n"

        return section

    def _format_detailed_results(self, results: dict) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã"""
        section = "### –ü—Ä–∏–º–µ—Ä—ã –ø—Ä–æ–≤–∞–ª–æ–≤\n\n"

        # –°–æ–±–∏—Ä–∞–µ–º –ø—Ä–æ–≤–∞–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã
        all_failures = []

        for category, items in results.items():
            for item in items:
                if not item.get('eval_result', {}).get('pass', True):
                    all_failures.append({
                        'category': category,
                        'item': item
                    })

        if all_failures:
            for failure in all_failures[:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5
                item = failure['item']
                section += f"**{failure['category']}**\n\n"
                section += f"- Query: `{item.get('query') or item.get('user_message', 'N/A')}`\n"
                section += f"- Score: {item['eval_result']['score']}/100\n"
                section += f"- Critique: {item['eval_result'].get('critique', 'N/A')}\n\n"
        else:
            section += "*–ù–µ—Ç –ø—Ä–æ–≤–∞–ª—å–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤*\n\n"

        return section

    def _generate_recommendations(self, results: dict) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
        recommendations = []

        # –ê–Ω–∞–ª–∏–∑ correctness
        salary_results = results.get('salary_correctness', [])
        if salary_results:
            avg_score = sum(r['eval_result']['score'] for r in salary_results) / len(salary_results)
            if avg_score < 80:
                recommendations.append("- –£–ª—É—á—à–∏—Ç—å —Ç–æ—á–Ω–æ—Å—Ç—å —Ä–∞—Å—á–µ—Ç–æ–≤ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã")

        vat_results = results.get('vat_correctness', [])
        if vat_results:
            avg_score = sum(r['eval_result']['score'] for r in vat_results) / len(vat_results)
            if avg_score < 80:
                recommendations.append("- –£–ª—É—á—à–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–π –ø–æ –ù–î–°")

        # –ê–Ω–∞–ª–∏–∑ safety
        adv_results = results.get('adversarial_safety', [])
        if adv_results:
            critical = sum(1 for r in adv_results if r['eval_result'].get('severity') in ['high', 'critical'])
            if critical > 0:
                recommendations.append("- **–ö–†–ò–¢–ò–ß–ù–û**: –£—Å—Ç—Ä–∞–Ω–∏—Ç—å —É—è–∑–≤–∏–º–æ—Å—Ç–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏")

        if not recommendations:
            recommendations.append("- –û—Ç–ª–∏—á–Ω–∞—è —Ä–∞–±–æ—Ç–∞! –ü—Ä–æ–¥–æ–ª–∂–∞–π—Ç–µ –≤ —Ç–æ–º –∂–µ –¥—É—Ö–µ.")

        return "\n".join(recommendations) + "\n"

    def _print_summary_table(self, results: dict):
        """–í—ã–≤–æ–¥–∏—Ç –∏—Ç–æ–≥–æ–≤—É—é —Ç–∞–±–ª–∏—Ü—É –≤ –∫–æ–Ω—Å–æ–ª—å"""
        table = Table(title="üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")

        table.add_column("–ö–∞—Ç–µ–≥–æ—Ä–∏—è", style="cyan")
        table.add_column("–í—Å–µ–≥–æ", justify="right")
        table.add_column("–ü—Ä–æ–π–¥–µ–Ω–æ", justify="right", style="green")
        table.add_column("Pass Rate", justify="right")
        table.add_column("Avg Score", justify="right")

        # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏
        categories = [
            ('Salary Correctness', results.get('salary_correctness', [])),
            ('VAT Correctness', results.get('vat_correctness', [])),
            ('Adversarial Safety', results.get('adversarial_safety', [])),
            ('Edge Case Safety', results.get('edge_case_safety', []))
        ]

        for name, items in categories:
            if items:
                total = len(items)
                passed = sum(1 for r in items if r['eval_result']['pass'])
                pass_rate = (passed / total * 100) if total > 0 else 0
                avg_score = sum(r['eval_result']['score'] for r in items) / total if total > 0 else 0

                table.add_row(
                    name,
                    str(total),
                    str(passed),
                    f"{pass_rate:.1f}%",
                    f"{avg_score:.1f}"
                )

        console.print("\n")
        console.print(table)

    def _get_model_name(self) -> str:
        import os
        return os.getenv('AGENT_MODEL', 'gemini-2.0-flash-exp')

    def _get_eval_model_name(self) -> str:
        import os
        return os.getenv('EVAL_MODEL', 'gemini-2.0-flash-thinking-exp-1219')

    def _get_current_date(self) -> str:
        from datetime import datetime
        return datetime.now().strftime('%Y-%m-%d %H:%M:%S')


if __name__ == '__main__':
    runner = EvalRunner()
    success = runner.run_all_evals()

    sys.exit(0 if success else 1)
